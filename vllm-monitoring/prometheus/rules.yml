groups:
- name: vllm_alerts
  rules:
  # vLLM服务可用性告警
  - alert: VLLMServiceDown
    expr: up{job="vllm-server"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "vLLM 服务不可用 [{{ $labels.instance }}]"
      description: "vLLM 服务已停止运行超过1分钟"

  # 请求队列积压告警
  - alert: HighRequestQueue
    expr: vllm_request_queue_size > 50
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "vLLM 请求队列积压 [{{ $labels.instance }}]"
      description: "vLLM 请求队列大小超过50已持续2分钟"

  # 响应时间过长告警
  - alert: SlowResponseTime
    expr: histogram_quantile(0.95, sum(rate(vllm_response_time_seconds_bucket[5m])) by (le, instance)) > 10
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "vLLM 响应时间过长 [{{ $labels.instance }}]"
      description: "vLLM 95%响应时间超过10秒已持续5分钟"

  # GPU内存使用率告警
  - alert: HighGpuMemoryUsage
    expr: (nvidia_gpu_memory_used_bytes / nvidia_gpu_memory_total_bytes) * 100 > 95
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "GPU内存使用率过高 [{{ $labels.instance }}]"
      description: "GPU内存使用率超过95%已持续5分钟"

  # Token生成速率低告警
  - alert: LowTokenThroughput
    expr: rate(vllm_total_tokens[5m]) < 1
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Token生成速率过低 [{{ $labels.instance }}]"
      description: "vLLM Token生成速率低于每秒1个已持续5分钟，可能存在性能问题" 